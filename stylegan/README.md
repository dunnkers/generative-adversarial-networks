# StyleGAN on Peregrine

This folder comes with code from the official StyleGAN repository as well as some job scripts. Designed specifically for the Peregrine RUG HPC.

## How to get going

1. First load the correct module: `module load TensorFlow/1.10.1-fosscuda-2018a-Python-3.6.4`
2. Then install all requirements with `pip install -r requirements.txt`

## Prepare the dataset

1. Make sure you have a large number of images ready (possibly generated by Thijs' script).
2. Modify `dataset_job.sh`
    1. Change `email@example.com` to your email address to keep track of the job's status.
    2. Change `STYLEGAN_PATH` to the (absolute) path of this folder.
    3. Change `IMAGES_PATH` to the (absolute) path where your large number of images reside.
3. Batch the job with `sbatch dataset_job.sh`

## Prepare the pre-trained network (FFHQ)

Run `python pickle_gan.py`. This will create a `network.pkl` file under `pickles`. *Note*: You might run into a Google Drive quota exceeded error. Try to run the script again later; if it still fails, contact Loran for the pickle file.

## Configure training

`train.py` specifies a number of options for the function `training_loop()` (defined in `training/training_loop.py`). Interesting stuff to change:

* `resume_run_pkl`: This will load `network.pkl` and allows to continue training.
* `resume_kimg` and `total_kimg`: These specify the image number the training loop is supposed to be at and how many images will have to be trained on in total, respectively. This has an influence on the learning rate and resolution schedule you will start training with.
* The number of GPUs used: Simply comment and uncomment the relevant lines for your setup.

There is a `train_job.sh` file for submitting a training run as a Peregrine job. Do the following:

1. Change `email@example.com` to your email address to keep track of the job's status.
2. Change `STYLEGAN_PATH` to the (absolute) path of this folder.

## Train the network

Either run `python train.py` for an interactive training run or `sbatch train_job.sh` to submit it as a job.
